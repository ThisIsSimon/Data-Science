{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "hispanic-soldier",
   "metadata": {},
   "source": [
    "# Motivations - Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "photographic-boxing",
   "metadata": {},
   "source": [
    "### Prediction:\n",
    "\n",
    "Accuracy of predicted value ($\\hat{Y}$) is dependent on two quantities, reducible error and irreducible error. Reducible error comes from creating a better estimate by reducing variance between predicted and actual, while irreducible is the variability.\n",
    "\n",
    "### Inference:\n",
    "\n",
    "Goal is to understand association between $Y$ and $X_1,...,X_P$. While we may estimate $f$, the goal is not to make a prediction. Examples of questions from ISLR:\n",
    "\n",
    "* Which predictors are associated with the response?\n",
    "\n",
    "Examples include identifying a few important predictors among a large set of possible variables.\n",
    "\n",
    "* What is the relationship between the response and each predictor?\n",
    "\n",
    "Understanding whether a negative (as $X_P$ increases, $Y$ decreases) or positive relationship is associated between the predictor and response.\n",
    "\n",
    "* Can the relationship between $Y$ and each predictor be adequately summarized using a linear equation, or is the relationship more complicated?\n",
    "\n",
    "### Parametric Methods\n",
    "\n",
    "Parametric methods involve a two-step model-based approach.\n",
    "\n",
    "1. An assumption is made about the functional form, or shape of $f$.\n",
    "2. After selecting a model, we need a procedure that uses the training data to fit or train the model.\n",
    "\n",
    "### Non-Parametric Methods\n",
    "\n",
    "While parametric methods make explicit assumptions about the functional form of $f$, Non-Parametric methods do not. They seek an estimate of $f$ that gets as close to the data points as possible without being too rough or wiggly.\n",
    "\n",
    "Major advantages over parametric approaches include having a potentially accurate fit of a wider range of possible shapes for $f$. But such methods suffer because they do not reduce the problem of estimating $f$ to a small number of parameters, therefore a very large number of observations is required to build an accurate estimate for $f$\n",
    "\n",
    "\n",
    "### Overfitting\n",
    "\n",
    "The model follow the errors, or noise, too closely."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elegant-student",
   "metadata": {},
   "source": [
    "# General Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparable-twelve",
   "metadata": {},
   "source": [
    "### Trade-Off Between Prediction Accuracy and Model Interpretability\n",
    "\n",
    "Figure and text from ISLR:\n",
    "\n",
    " ![flexibility_vs_interpretability](ISLR_IMG_SNIPPETS/flex_interpret.PNG)\n",
    " \n",
    "<b>FIGURE 2.7.</b> A representation of the tradeoff between flexibility and interpretability, using different statistical learning methods. In general, as the flexibility of a method increases, its interpretability decreases.\n",
    "\n",
    "#### Why would we ever choose to use a more restrictive method instead of a very flexible approach?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chronic-master",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
